<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>windows引导问题</title>
    <url>/2020/04/21/windows%E5%BC%95%E5%AF%BC%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<blockquote>
<p><strong>在windows系统下直接对ubuntu系统所在磁盘进行格式化，会导致开机提示grub rescue问题,解决方案如下：</strong></p>
</blockquote>
<h3 id="1、利用软碟通做一个ubuntu启动u盘。"><a href="#1、利用软碟通做一个ubuntu启动u盘。" class="headerlink" title="1、利用软碟通做一个ubuntu启动u盘。"></a>1、利用软碟通做一个ubuntu启动u盘。</h3><p><a href="https://jingyan.baidu.com/article/574c52195fa5586c8c9dc176.html" target="_blank" rel="noopener">传送门</a></p>
<h3 id="2、进入ubuntu试用系统，操作步骤如下："><a href="#2、进入ubuntu试用系统，操作步骤如下：" class="headerlink" title="2、进入ubuntu试用系统，操作步骤如下："></a>2、进入ubuntu试用系统，操作步骤如下：</h3><pre><code>sudo apt-get install lilo
sudo lilo -M /dev/sda mbr</code></pre>]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>windows+ubuntu双系统安装</title>
    <url>/2020/04/21/windows-ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<blockquote>
<ol>
<li><strong>windows版本：win8.1</strong></li>
<li><strong>笔记本型号：戴尔灵越</strong></li>
</ol>
</blockquote>
<hr>
<h3 id="1、整体流程"><a href="#1、整体流程" class="headerlink" title="1、整体流程"></a>1、<a href="https://blog.csdn.net/stu_shanghui/article/details/101865463" target="_blank" rel="noopener">整体流程</a></h3><h3 id="2、对1所配置ubuntu系统空间调整如下"><a href="#2、对1所配置ubuntu系统空间调整如下" class="headerlink" title="2、对1所配置ubuntu系统空间调整如下"></a>2、对1所配置ubuntu系统空间调整如下</h3><ol>
<li>swap：4G</li>
<li>boot：800mb</li>
<li>/:25G</li>
<li>/home：剩余所有空间</li>
</ol>
<hr>
<blockquote>
<ol>
<li><strong>注意：对于本人，无法使用快速u盘启动安装ubuntu系统，需要配置u盘为第一启动项后安装。</strong></li>
<li><strong>对于注意的解释：快速u盘启动安装的是uefi类型，而u盘第一启动项是efi类型，根据个人本子情况随时调节。</strong></li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>ROS安装</title>
    <url>/2020/04/21/ROS%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<blockquote>
<p><strong>ubuntu16.04下ROS安装</strong></p>
</blockquote>
<h3 id="1、ubuntu换源提高下载速度（可省）"><a href="#1、ubuntu换源提高下载速度（可省）" class="headerlink" title="1、ubuntu换源提高下载速度（可省）"></a>1、ubuntu换源提高下载速度（可省）</h3><h3 id="2、解决课程出现的ubuntu-锁问题（可省）"><a href="#2、解决课程出现的ubuntu-锁问题（可省）" class="headerlink" title="2、解决课程出现的ubuntu 锁问题（可省）"></a>2、解决课程出现的ubuntu 锁问题（可省）</h3><h3 id="3、ROS安装"><a href="#3、ROS安装" class="headerlink" title="3、ROS安装"></a>3、ROS安装</h3>]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>初学tensorflow-自编码</title>
    <url>/2020/04/05/%E5%88%9D%E5%AD%A6tensorflow-%E8%87%AA%E7%BC%96%E7%A0%81/</url>
    <content><![CDATA[<blockquote>
<p><strong>我理解的自编码是对原数据进行降维处理，从而能够减少无用特征，提高模型效率。以下对MNIST数据集进行自编码处理。</strong></p>
</blockquote>
<h3 id="1、导入功能包"><a href="#1、导入功能包" class="headerlink" title="1、导入功能包"></a>1、导入功能包</h3><pre><code>import tensorflow.compat.v1 as tf
tf.disable_eager_execution()
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.examples.tutorials.mnist import input_data</code></pre><hr>
<h3 id="2、下载数据集"><a href="#2、下载数据集" class="headerlink" title="2、下载数据集"></a>2、下载数据集</h3><pre><code>mnist = input_data.read_data_sets(&quot;/tmp/data/&quot;, one_hot=False)</code></pre><hr>
<h3 id="3、配置参数"><a href="#3、配置参数" class="headerlink" title="3、配置参数"></a>3、配置参数</h3><pre><code>learning_rate = 0.01
training_epochs = 5
batch_size = 256
examples_to_show = 10
n_input = 784
n_hidden_1 = 256 # 1st layer num features
n_hidden_2 = 128 # 2nd layer num features</code></pre><ul>
<li>从上到下依次是学习率、训练轮数、批数据、测试个数、MNIST数据集原始维度、两个隐层的节点数。</li>
</ul>
<hr>
<h3 id="4、权重与偏置"><a href="#4、权重与偏置" class="headerlink" title="4、权重与偏置"></a>4、权重与偏置</h3><pre><code>weights = {
    &apos;encoder_h1&apos;: tf.Variable(tf.random_normal([n_input, n_hidden_1])),
    &apos;encoder_h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),
    &apos;decoder_h1&apos;: tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),
    &apos;decoder_h2&apos;: tf.Variable(tf.random_normal([n_hidden_1, n_input])),
            }
biases = {
    &apos;encoder_b1&apos;: tf.Variable(tf.random_normal([n_hidden_1])),
    &apos;encoder_b2&apos;: tf.Variable(tf.random_normal([n_hidden_2])),
    &apos;decoder_b1&apos;: tf.Variable(tf.random_normal([n_hidden_1])),
    &apos;decoder_b2&apos;: tf.Variable(tf.random_normal([n_input])),
            }</code></pre><ul>
<li>权重与偏置，两层用于自编码的压缩，两层用于自编码的解压。</li>
<li>以解压后的数据与原数据做对比，计算损失，进行优化。</li>
</ul>
<hr>
<h3 id="5、模型输入"><a href="#5、模型输入" class="headerlink" title="5、模型输入"></a>5、模型输入</h3><pre><code>X = tf.placeholder(&quot;float&quot;, [None, n_input])</code></pre><hr>
<h3 id="6、模型（压缩与解压）"><a href="#6、模型（压缩与解压）" class="headerlink" title="6、模型（压缩与解压）"></a>6、模型（压缩与解压）</h3><pre><code>def encoder(x):
layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[&apos;encoder_h1&apos;]),
                               biases[&apos;encoder_b1&apos;]))
layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[&apos;encoder_h2&apos;]),
                               biases[&apos;encoder_b2&apos;]))
return layer_2

def decoder(x):
layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights[&apos;decoder_h1&apos;]),
                               biases[&apos;decoder_b1&apos;]))
layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights[&apos;decoder_h2&apos;]),
                               biases[&apos;decoder_b2&apos;]))
return layer_2
encoder_op = encoder(X)
pred = decoder(encoder_op)</code></pre><ul>
<li>有关第一个方法，采用sigmoid激活函数，对数据进行压缩，压缩后的维度为256.layer2继续压缩，后维度为128.</li>
<li>有关第二个方法，根据压缩后的数据进行复原，以128维扩展至256维，扩展至784维。</li>
</ul>
<hr>
<h3 id="7、模型编译"><a href="#7、模型编译" class="headerlink" title="7、模型编译"></a>7、模型编译</h3><pre><code>cost = tf.reduce_mean(tf.pow(X - pred, 2))
optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)</code></pre><ul>
<li>注意此处的误差计算方式，目前没有理解。</li>
</ul>
<hr>
<h3 id="8、模型训练并测试测试集"><a href="#8、模型训练并测试测试集" class="headerlink" title="8、模型训练并测试测试集"></a>8、模型训练并测试测试集</h3><pre><code>with tf.Session() as sess:
    init = tf.global_variables_initializer()
    sess.run(init)
    total_batch = int(mnist.train.num_examples / batch_size)
    for epoch in range(training_epochs):
        for i in range(total_batch):
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  # max(x) = 1, min(x) = 0
            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})
        print(&quot;Epoch:&quot;, &apos;%04d&apos; % (epoch+1),
              &quot;cost=&quot;, &quot;{:.9f}&quot;.format(c))
print(&quot;Optimization Finished!&quot;)
！！！#test
encode_decode = sess.run(
    pred, feed_dict={X: mnist.test.images[:examples_to_show]})
f, a = plt.subplots(2, 10, figsize=(10, 2))
for i in range(examples_to_show):
    a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))
    a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))
plt.show()</code></pre><ul>
<li>第一部分用于训练，每次丢入256个数据进行训练，至全部丢入为一个epoch，共训练10轮epoch。<code>_, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})</code>run运行[optimizer, cost]，其实只需一个optimzer即可，但是为了显示每一轮epoch后的损失，将其加入至run，反馈回cost用于输出。</li>
<li>第二部分用于测试与画图，画图部分暂时未精确学习，后续。</li>
</ul>
<hr>
<h3 id="9、代码已上传本人github-其主要根据莫烦代码修改而成。"><a href="#9、代码已上传本人github-其主要根据莫烦代码修改而成。" class="headerlink" title="9、代码已上传本人github,其主要根据莫烦代码修改而成。"></a>9、代码已上传<a href="https://github.com/Gtt-rgb/study_tensorflow" target="_blank" rel="noopener">本人github</a>,其主要根据莫烦代码修改而成。</h3><h3 id="参考文献：1、莫烦tensorflow教程"><a href="#参考文献：1、莫烦tensorflow教程" class="headerlink" title="参考文献：1、莫烦tensorflow教程"></a>参考文献：1、<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/3-4-A-speed-up-learning/" target="_blank" rel="noopener">莫烦tensorflow教程</a></h3>]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>初学tensorflow-RNN</title>
    <url>/2020/04/05/%E5%88%9D%E5%AD%A6tensorflow-RNN/</url>
    <content><![CDATA[<blockquote>
<p><strong>使用RNN对MNIST数据集分类</strong></p>
</blockquote>
<h3 id="1、-功能包导入"><a href="#1、-功能包导入" class="headerlink" title="1、 功能包导入"></a>1、 功能包导入</h3><pre><code>import tensorflow.compat.v1 as tf
tf.disable_eager_execution()
from tensorflow.examples.tutorials.mnist import input_data</code></pre><hr>
<h3 id="2、数据集下载"><a href="#2、数据集下载" class="headerlink" title="2、数据集下载"></a>2、数据集下载</h3><pre><code>mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</code></pre><hr>
<h3 id="3、参数配置"><a href="#3、参数配置" class="headerlink" title="3、参数配置"></a>3、参数配置</h3><pre><code>lr = 0.001#学习率
training_iters = 100#训练轮数
batch_size = 128
n_inputs = 28
n_steps = 28
n_hidden_units = 128
n_classes = 10</code></pre><hr>
<ul>
<li>lr为网络学习率，training_iters为训练轮数，batch_size为每次丢入网络的simple，n_inputs是输入层的结点个数（MNIST每张图片是28*28，每行28个像素点作为网络的输入，28步后可以将整张图片全部输入），n_steps是步数（28步之后可以将整张图片输入）。n_hidden_units为隐层个数，即ceil中的结点个数.n_classes是10个类别。</li>
</ul>
<hr>
<h3 id="4、权重、偏置初始化"><a href="#4、权重、偏置初始化" class="headerlink" title="4、权重、偏置初始化"></a>4、权重、偏置初始化</h3><pre><code>weights = {
&apos;in&apos;: tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),
&apos;out&apos;: tf.Variable(tf.random_normal([n_hidden_units, n_classes]))
}# (28, 128)、# (128, 10)
biases = {
&apos;in&apos;: tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),
&apos;out&apos;: tf.Variable(tf.constant(0.1, shape=[n_classes, ]))
}# (128, )、# (10, )</code></pre><ul>
<li>输入数据，经过权重与偏置计算到达ceil，在ceil处理之后通过权重与偏置计算输出。</li>
<li>以上为输入与输出的权重、偏置。</li>
</ul>
<hr>
<h3 id="5、网络输入"><a href="#5、网络输入" class="headerlink" title="5、网络输入"></a>5、网络输入</h3><pre><code>#input
xs = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
ys = tf.placeholder(tf.float32, [None, n_classes])</code></pre><ul>
<li>MNIST数据为simple<em>784，需要将其还原为28</em>28结构。</li>
<li>10分类，采用one_hot编码，同样需要将label重塑为[simple.10]结构。</li>
</ul>
<hr>
<h3 id="6、RNN隐层"><a href="#6、RNN隐层" class="headerlink" title="6、RNN隐层"></a>6、RNN隐层</h3><pre><code>def RNN(X, weights, biases):#输入，权重，偏置
    X = tf.reshape(X, [-1, 28])#(128 * 28, 28 )
    X_in = tf.matmul(X, weights[&apos;in&apos;]) + biases[&apos;in&apos;]#(128 * 28, 128 )
    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])#(128 ，28, 128 )#时间序列
    cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)
    init_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)
    outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False)#time_major代表时间序列
    outputs = tf.unstack(tf.transpose(outputs, [1, 0, 2]))
    results = tf.matmul(outputs[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]#(另外一种定义方法，不理解)results = tf.matmul(final_state[1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]#应该是仅仅考虑了短期记忆
    return results
pred = RNN(xs, weights, biases)</code></pre><ul>
<li>形参（输入数据、权重、偏置）</li>
<li>将数据重塑为[simple*28,28]结构，使数据能够根据权重进行计算，计算完成后需要继续重塑，目的是能够以时间序列输入至ceil中，重塑后的结构为[simple.28.128]，(其中simple是进入的数据个数，28是时间序列，128是数据根据权重计算出来的新维度)。</li>
<li>init_state中，需要对batch_size进行初始化，目的是为每张图片增添一个可传递的记忆状态。（每张图片分28步进行，RNN根据之前的记忆与当前的输入进行分类或回归）</li>
<li><code>tf.nn.dynamic_rnn</code>暂时理解为融合当前数据与记忆得出的结果。<br><img src="/2020/04/05/%E5%88%9D%E5%AD%A6tensorflow-RNN/22.jpg" alt="图片来源为https://www.zhihu.com/question/41949741?sort=created"></li>
</ul>
<hr>
<h3 id="7、网络编译"><a href="#7、网络编译" class="headerlink" title="7、网络编译"></a>7、网络编译</h3><pre><code>cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=ys))
train_op = tf.train.AdamOptimizer(lr).minimize(cost)</code></pre><ul>
<li>采用交叉熵损失计算方法与Adam优化器</li>
</ul>
<hr>
<h3 id="8、参数初始化与网络训练"><a href="#8、参数初始化与网络训练" class="headerlink" title="8、参数初始化与网络训练"></a>8、参数初始化与网络训练</h3><pre><code>with tf.Session() as sess:
    init = tf.global_variables_initializer()
    sess.run(init)
    for i in range(training_iters):
        batch_xs, batch_ys = mnist.train.next_batch(128)
        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])
        sess.run(train_op, feed_dict={xs: batch_xs, ys: batch_ys})</code></pre><hr>
<h3 id="9、代码已上传本人github-其主要根据莫烦代码修改而成。"><a href="#9、代码已上传本人github-其主要根据莫烦代码修改而成。" class="headerlink" title="9、代码已上传本人github,其主要根据莫烦代码修改而成。"></a>9、代码已上传<a href="https://github.com/Gtt-rgb/study_tensorflow" target="_blank" rel="noopener">本人github</a>,其主要根据莫烦代码修改而成。</h3><h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p>1、<a href="https://www.zhihu.com/question/41949741?sort=created" target="_blank" rel="noopener">RNN输入输出详解</a><br>2、<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/3-4-A-speed-up-learning/" target="_blank" rel="noopener">莫烦tensorflow教程</a></p>
]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>初学tensorflow-CNN</title>
    <url>/2020/04/03/%E5%88%9D%E5%AD%A6tensorflow-CNN/</url>
    <content><![CDATA[<blockquote>
<p><strong>使用CNN对MNIST分类。</strong></p>
</blockquote>
<h3 id="1、导入功能包"><a href="#1、导入功能包" class="headerlink" title="1、导入功能包"></a>1、导入功能包</h3><pre><code>import tensorflow.compat.v1 as tf
tf.disable_eager_execution()
from tensorflow.examples.tutorials.mnist import input_data</code></pre><hr>
<h3 id="2、下载MNIST数据集"><a href="#2、下载MNIST数据集" class="headerlink" title="2、下载MNIST数据集"></a>2、下载MNIST数据集</h3><pre><code>mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</code></pre><hr>
<h3 id="3、定义权重方法"><a href="#3、定义权重方法" class="headerlink" title="3、定义权重方法"></a>3、定义权重方法</h3><pre><code>def weight_variable(shape):
    initial = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(initial)</code></pre><ul>
<li>此处使用的是truncated_normal（）方法进行初始化权重，在CNN效果好。</li>
</ul>
<hr>
<h3 id="4、定义偏置方法"><a href="#4、定义偏置方法" class="headerlink" title="4、定义偏置方法"></a>4、定义偏置方法</h3><pre><code>def bias_variable(shape):
    initial = tf.constant(0.1, shape=shape)
    return tf.Variable(initial)</code></pre><hr>
<hr>
<h3 id="5、定义卷积层方法"><a href="#5、定义卷积层方法" class="headerlink" title="5、定义卷积层方法"></a>5、定义卷积层方法</h3><pre><code>def conv2d(x, W):
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)</code></pre><ul>
<li>x代表输入image，结构为[simple个数(一般用-1)，图片长，图片宽，图片通道]。w为权重，结构为[卷积核长，卷积核宽，卷积核通道(要与图片通道相等)，卷积核个数]。strides为步长，[固定，x轴移动步数，Y轴移动步数，固定]，pading为全0填充。参考下图可以加深卷积核的理解，重点是理解输出通道以及计算方式。<br><img src="/2020/04/03/%E5%88%9D%E5%AD%A6tensorflow-CNN/%E5%8D%B7%E7%A7%AF.jpg" alt="卷积核"></li>
</ul>
<hr>
<h3 id="6、定义模型输入"><a href="#6、定义模型输入" class="headerlink" title="6、定义模型输入"></a>6、定义模型输入</h3><pre><code>xs = tf.placeholder(tf.float32, [None, 784])#/255. # 28x28
ys = tf.placeholder(tf.float32, [None, 10])
keep_prob = tf.placeholder(tf.float32)
x_image = tf.reshape(xs, [-1, 28, 28, 1])#转换维度[全部例子，图片长，图片宽，图片通道个数]</code></pre><ul>
<li>mnist数据集被拉成一串，为784列(28<em>28)，所以xs结构为[none，784]。keep_prob为dropout。将mnist数据集还原为28</em>28结构，用作卷积神经网络的输入，x_image作用既如此。</li>
</ul>
<hr>
<h3 id="7、定义模型卷积、池化层"><a href="#7、定义模型卷积、池化层" class="headerlink" title="7、定义模型卷积、池化层"></a>7、定义模型卷积、池化层</h3><pre><code>W_conv1 = weight_variable([5,5, 1,32]) #[卷积核长，卷积核宽，输入图片通道个数，输出图片通道个数]
b_conv1 = bias_variable([32])
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) #28x28x32
h_pool1 = max_pool_2x2(h_conv1)#14*14*32
W_conv2 = weight_variable([5,5, 32,64]) #[卷积核长，卷积核宽，输入图片通道个数，输出图片通道个数]
b_conv2 = bias_variable([64])
h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) #14x14x64
h_pool2 = max_pool_2x2(h_conv2)#7*7*64</code></pre><ul>
<li>采用最大池化max_pool_2<em>2（）方法，两层卷积池化后图片结构为7</em>7*64，不断卷积池化的过程就是将图片变小变厚的过程。</li>
</ul>
<hr>
<h3 id="8、定义模型平坦层"><a href="#8、定义模型平坦层" class="headerlink" title="8、定义模型平坦层"></a>8、定义模型平坦层</h3><pre><code>h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])#-1代表全部例子</code></pre><ul>
<li>平坦层后接全连接层，需要对池化后的数据在进行变形，将其拉成一串。结构为[所有的simple，将[7，7，14]结构转换为7<em>7</em>14]。作为全连接网络的输入。</li>
</ul>
<hr>
<h3 id="9、定义模型全连接层"><a href="#9、定义模型全连接层" class="headerlink" title="9、定义模型全连接层"></a>9、定义模型全连接层</h3><pre><code>W_fc1 = weight_variable([7*7*64, 1024])
b_fc1 = bias_variable([1024])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])
prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)</code></pre><ul>
<li>注意此处使用了dropout方法，通过每次训练过程，使部分神经元不激活，从而避免了过拟合现象。所谓过拟合，即在训练集损失很低，在测试集损失确很高。</li>
<li>此处使用了两层隐层，激活函数使用softmax，因为要做分类。</li>
</ul>
<hr>
<h3 id="10、模型编译"><a href="#10、模型编译" class="headerlink" title="10、模型编译"></a>10、模型编译</h3><pre><code>cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),
                                          reduction_indices=[1])) 
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</code></pre><ul>
<li>采用交叉熵方法计算损失。</li>
<li>采用Adam优化器进行参数优化。</li>
</ul>
<hr>
<h3 id="11、参数初始化"><a href="#11、参数初始化" class="headerlink" title="11、参数初始化"></a>11、参数初始化</h3><pre><code>sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)</code></pre><hr>
<h3 id="12、模型训练"><a href="#12、模型训练" class="headerlink" title="12、模型训练"></a>12、模型训练</h3><pre><code>for i in range(1000):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})</code></pre><ul>
<li>每次丢入模型100个数据进行训练，其结果并不会比全部数据丢入模型效果差。</li>
</ul>
<hr>
<h3 id="13、定义模型评估方法"><a href="#13、定义模型评估方法" class="headerlink" title="13、定义模型评估方法"></a>13、定义模型评估方法</h3><pre><code>def compute_accuracy(v_xs, v_ys):
    global prediction            
    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})
    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})
    return result</code></pre><ul>
<li>计算准确率。</li>
</ul>
<hr>
<pre><code>print(compute_accuracy(
    mnist.test.images[:1000], mnist.test.labels[:1000]))</code></pre><hr>
<h3 id="14、代码已上传本人github-其主要根据莫烦代码修改而成。"><a href="#14、代码已上传本人github-其主要根据莫烦代码修改而成。" class="headerlink" title="14、代码已上传本人github,其主要根据莫烦代码修改而成。"></a>14、代码已上传<a href="https://github.com/Gtt-rgb/study_tensorflow" target="_blank" rel="noopener">本人github</a>,其主要根据莫烦代码修改而成。</h3><h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p>1、<a href="https://tieba.baidu.com/p/5148050240?red_tag=3270728623" target="_blank" rel="noopener">神经网络黑盒的简单解释(推荐)</a><br>2、<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/3-4-A-speed-up-learning/" target="_blank" rel="noopener">莫烦tensorflow教程</a></p>
]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>链接</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>初学tensorflow-分类</title>
    <url>/2020/04/02/%E5%88%9D%E5%AD%A6tensorflow-%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<blockquote>
<p><strong>学习使用tensorflow的数字10分类教程</strong></p>
</blockquote>
<h3 id="1、导入功能包"><a href="#1、导入功能包" class="headerlink" title="1、导入功能包"></a>1、导入功能包</h3><pre><code>import tensorflow.compat.v1 as tf
tf.disable_eager_execution()
from tensorflow.examples.tutorials.mnist import input_data</code></pre><hr>
<h3 id="2、下载数据集"><a href="#2、下载数据集" class="headerlink" title="2、下载数据集"></a>2、下载数据集</h3><pre><code>mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</code></pre><hr>
<h3 id="3、设计隐层权重、偏置"><a href="#3、设计隐层权重、偏置" class="headerlink" title="3、设计隐层权重、偏置"></a>3、设计隐层权重、偏置</h3><pre><code>def add_layer(inputs, in_size, out_size, activation_function=None,):
    Weights = tf.Variable(tf.random_normal([in_size, out_size]))
    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)
    Wx_plus_b = tf.matmul(inputs, Weights) + biases
    if activation_function is None:
        outputs = Wx_plus_b
    else:
        outputs = activation_function(Wx_plus_b,)
    return outputs</code></pre><hr>
<h3 id="4、模型输入"><a href="#4、模型输入" class="headerlink" title="4、模型输入"></a>4、模型输入</h3><pre><code>xs = tf.placeholder(tf.float32, [None, 784])
ys = tf.placeholder(tf.float32, [None, 10])</code></pre><ul>
<li>此题的输入图像为28*28个像素点，需要全部输入网络中训练，所以输入结构为784列。另外此教程为10分类问题，输出结构为10列（one-hot编码）。</li>
</ul>
<hr>
<h3 id="5、模型隐层"><a href="#5、模型隐层" class="headerlink" title="5、模型隐层"></a>5、模型隐层</h3><pre><code>prediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)</code></pre><ul>
<li>此处与回归模型不同，使用的是softmax激活函数，本次设计1层隐层。</li>
</ul>
<hr>
<h3 id="6、模型编译"><a href="#6、模型编译" class="headerlink" title="6、模型编译"></a>6、模型编译</h3><pre><code>cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),
                                                      reduction_indices=[1])) 
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</code></pre><ul>
<li>注意此处计算误差的方式也与回归有区别，此处暂时理解为与激活函数对应。优化器有多种方案，同回归一样。</li>
</ul>
<hr>
<h3 id="7、初始化参数"><a href="#7、初始化参数" class="headerlink" title="7、初始化参数"></a>7、初始化参数</h3><pre><code>sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)</code></pre><hr>
<h3 id="8、模型训练"><a href="#8、模型训练" class="headerlink" title="8、模型训练"></a>8、模型训练</h3><pre><code>for i in range(1000):
    batch_xs, batch_ys = mnist.train.next_batch(100)
       sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})</code></pre><ul>
<li>每次训练时并没有把全部数据丢入模型进行训练，此处使用的是全部数据集的100个数据，依据莫烦教程讲解，100个数据依旧能把模型训练的很好。</li>
</ul>
<hr>
<h3 id="9、模型评估"><a href="#9、模型评估" class="headerlink" title="9、模型评估"></a>9、模型评估</h3><pre><code>def compute_accuracy(v_xs, v_ys):
    global prediction
    y_pre = sess.run(prediction, feed_dict={xs: v_xs})
    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))#计算准确率
    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})
    return result</code></pre><ul>
<li>定义模型评估函数</li>
</ul>
<hr>
<pre><code>print(compute_accuracy(
    mnist.test.images, mnist.test.labels))</code></pre><ul>
<li>输出测试集的准确率，评估模型。</li>
</ul>
<hr>
<h3 id="10、代码已上传本人github-其主要根据莫烦代码修改而成。"><a href="#10、代码已上传本人github-其主要根据莫烦代码修改而成。" class="headerlink" title="10、代码已上传本人github,其主要根据莫烦代码修改而成。"></a>10、代码已上传<a href="https://github.com/Gtt-rgb/study_tensorflow" target="_blank" rel="noopener">本人github</a>,其主要根据莫烦代码修改而成。</h3><h3 id="参考文献：1、莫烦tensorflow教程"><a href="#参考文献：1、莫烦tensorflow教程" class="headerlink" title="参考文献：1、莫烦tensorflow教程"></a>参考文献：1、<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/3-4-A-speed-up-learning/" target="_blank" rel="noopener">莫烦tensorflow教程</a></h3><blockquote>
<p><strong>注意：在tensorflow2.0版本是不存在MNIST教程的，需要额外下载。<a href="https://www.lagou.com/lgeduarticle/72591.html" target="_blank" rel="noopener">下载教程</a></strong></p>
</blockquote>
]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>初学tensorflow-tensorboard使用</title>
    <url>/2020/04/02/%E5%88%9D%E5%AD%A6tensorflow-tensorboard%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<blockquote>
<p><strong>在线性回归基础上，利用tensorboard进行可视化。</strong></p>
</blockquote>
<h3 id="1、显示网络框架"><a href="#1、显示网络框架" class="headerlink" title="1、显示网络框架"></a>1、显示网络框架</h3><pre><code>with tf.name_scope(&apos;inputs&apos;):
   xs = tf.placeholder(tf.float32, [None, 1], name=&apos;x_input&apos;)
   ys = tf.placeholder(tf.float32, [None, 1], name=&apos;y_input&apos;)</code></pre><ul>
<li>例子如上：可视化1线性回归的输入层。通过<code>with tf.name_scope(xxx):</code>命令可以可视化网络的任意结构。</li>
</ul>
<hr>
<h3 id="2、显示权重、偏置数据"><a href="#2、显示权重、偏置数据" class="headerlink" title="2、显示权重、偏置数据"></a>2、显示权重、偏置数据</h3><pre><code>Weights = tf.Variable(tf.random_normal([in_size, out_size]), name=&apos;W&apos;)
tf.summary.histogram(layer_name + &apos;/weights&apos;, Weights)</code></pre><ul>
<li>例子如上：可视化权重数据。通过<code>tf.summary.histogram（xxx，xxx）</code>可视化数据信息。</li>
</ul>
<hr>
<h3 id="3、显示损失数据"><a href="#3、显示损失数据" class="headerlink" title="3、显示损失数据"></a>3、显示损失数据</h3><pre><code>loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),
                                        reduction_indices=[1]))
tf.summary.scalar(&apos;loss&apos;, loss)</code></pre><ul>
<li>例子如上：可视化损失数据。通过<code>tf.summary.scalar(xxx, loss)</code>可视化损失信息。</li>
</ul>
<hr>
<h3 id="4、（1，2，3）步需要以下命令相配合"><a href="#4、（1，2，3）步需要以下命令相配合" class="headerlink" title="4、（1，2，3）步需要以下命令相配合"></a>4、（1，2，3）步需要以下命令相配合</h3><pre><code>sess = tf.Session()
writer = tf.summary.FileWriter(&quot;logs/&quot;, sess.graph)
merged = tf.summary.merge_all()</code></pre><ul>
<li>含义：建立文件，存储融合数据。</li>
<li>注意：此时没有数据，显示的是网络结构与数据框图。</li>
</ul>
<hr>
<pre><code>result = sess.run(merged,
                          feed_dict={xs: x_data, ys: y_data})
writer.add_summary(result, i)</code></pre><ul>
<li>含义：将数据丢入模型（此处丢入的是merged，不是train！！），得到一批数据，将数据加入到数据融合文件，系统会自动将数据显示在数据框图中。</li>
</ul>
<hr>
<h3 id="5、可视化截图"><a href="#5、可视化截图" class="headerlink" title="5、可视化截图"></a>5、可视化截图</h3><ul>
<li>tensorboard启动：在存储数据文件目录下，输入<code>tensorboard --logdir==“logs\”</code>，在浏览器输入<code>localhost：6006</code>即可。</li>
</ul>
<hr>
<h2 id><a href="#" class="headerlink" title></a><img src="/2020/04/02/%E5%88%9D%E5%AD%A6tensorflow-tensorboard%E4%BD%BF%E7%94%A8/%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.jpg" alt="1、网络结构"></h2><h2 id="-1"><a href="#-1" class="headerlink" title></a><img src="/2020/04/02/%E5%88%9D%E5%AD%A6tensorflow-tensorboard%E4%BD%BF%E7%94%A8/%E6%9D%83%E9%87%8D%E5%8F%8A%E5%81%8F%E7%BD%AE%E6%95%B0%E6%8D%AE.jpg" alt="2、权重及偏置"></h2><p><img src="/2020/04/02/%E5%88%9D%E5%AD%A6tensorflow-tensorboard%E4%BD%BF%E7%94%A8/%E6%8D%9F%E5%A4%B1.jpg" alt="3、损失"></p>
<hr>
<h3 id="6、代码已上传本人github-其主要根据莫烦代码修改而成。"><a href="#6、代码已上传本人github-其主要根据莫烦代码修改而成。" class="headerlink" title="6、代码已上传本人github,其主要根据莫烦代码修改而成。"></a>6、代码已上传<a href="https://github.com/Gtt-rgb/study_tensorflow" target="_blank" rel="noopener">本人github</a>,其主要根据莫烦代码修改而成。</h3><blockquote>
<p><strong>注意：计算机名需要设置为英文，中文情况下生成的tensorboard文件乱码</strong></p>
</blockquote>
<h3 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h3><p>1、<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/3-4-A-speed-up-learning/" target="_blank" rel="noopener">莫烦tensorflow教程</a></p>
]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>git使用</title>
    <url>/2020/04/01/git%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<blockquote>
<p><strong>利用git建立本地仓库管理文章与代码，及上传至github</strong></p>
<h2 id="1、利用git管理本地仓库并上传github"><a href="#1、利用git管理本地仓库并上传github" class="headerlink" title="1、利用git管理本地仓库并上传github"></a>1、<a href="https://baijiahao.baidu.com/s?id=1619544681032320225&wfr=spider&for=pc" target="_blank" rel="noopener">利用git管理本地仓库并上传github</a></h2><p><strong>&gt; 可选</strong><br>1、<a href="https://www.yiibai.com/git/git_push.html" target="_blank" rel="noopener">git教程(全)</a><br>2、<a href="https://blog.csdn.net/qq_32384249/article/details/73038413?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">git找回本地误删的文件</a></p>
</blockquote>
]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>初学tensorflow-线性回归</title>
    <url>/2020/04/01/%E5%88%9D%E5%AD%A6tensorflow-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<blockquote>
<p><strong>通过tensorflow拟合y=a^2-0.5+槽点，以下为代码，分步解析</strong></p>
</blockquote>
<h3 id="1、导入功能包"><a href="#1、导入功能包" class="headerlink" title="1、导入功能包"></a>1、导入功能包</h3><pre><code>import tensorflow.compat.v1 as tf
tf.disable_eager_execution()
import numpy as np
import matplotlib.pyplot as plt</code></pre><h3 id="2、设置需要拟合的函数及数据"><a href="#2、设置需要拟合的函数及数据" class="headerlink" title="2、设置需要拟合的函数及数据"></a>2、设置需要拟合的函数及数据</h3><pre><code>x_data = np.linspace(-1, 1, 300, dtype=np.float32)[:, np.newaxis]
noise = np.random.normal(0, 0.05, x_data.shape).astype(np.float32)
y_data = np.square(x_data) - 0.5 + noise</code></pre><h3 id="3、设计隐层的权重、偏置等"><a href="#3、设计隐层的权重、偏置等" class="headerlink" title="3、设计隐层的权重、偏置等"></a>3、设计隐层的权重、偏置等</h3><pre><code>def add_layer(inputs, in_size, out_size, activation_function=None):
    Weights = tf.Variable(tf.random_normal([in_size, out_size]))
    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)
    Wx_plus_b = tf.matmul(inputs, Weights) + biases
    if activation_function is None:
        outputs = Wx_plus_b
    else:
        outputs = activation_function(Wx_plus_b)
    return outputs</code></pre><ul>
<li>偏置不能设置为0，令其加0.1.权重用numpy数组随机初始化，通常比全零效果好。</li>
<li>input为输入数据，insize为输入维度，outsize为输出维度，activation_function为激活函数。</li>
<li>tf.variable为tensorflow的变量声明，tf.constant表示常量，tf.add(a,b)表示相加，tf.assign(a,b)表示将b赋值给a，tf.matmul(a,b)表示相乘。<h3 id="4、设计网络的输入层"><a href="#4、设计网络的输入层" class="headerlink" title="4、设计网络的输入层"></a>4、设计网络的输入层</h3>  <code>xs = tf.placeholder(tf.float32, [None, 1])
   ys = tf.placeholder(tf.float32, [None, 1])</code></li>
<li>tensorflow通过占位符placeholder来进行数据的输入，[None,1]表示任意行1列的数据，必须包括类型<h3 id="5、设计网络的隐层"><a href="#5、设计网络的隐层" class="headerlink" title="5、设计网络的隐层"></a>5、设计网络的隐层</h3>  <code>l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)
   prediction = add_layer(l1, 10, 1, activation_function=None)</code></li>
<li>回归一般用relu函数即可。如上，隐层为两层，每层包含10个神经元。<h3 id="6、模型编译"><a href="#6、模型编译" class="headerlink" title="6、模型编译"></a>6、模型编译</h3>  <code>loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))
   train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)</code></li>
<li>设计网络的损失函数与优化器，常用的优化器还包括SGD、Adam、Momentum等，优化器能加速网络的训练速度，与学习率相关。<h3 id="7、参数初始化"><a href="#7、参数初始化" class="headerlink" title="7、参数初始化"></a>7、参数初始化</h3><code>sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)</code></li>
<li>整个程序内只要包含变量，必须用tf.global——进行初始化。另外，所有的操作都必须通过会话即session.run(xxx)来执行。<h3 id="8、模型训练"><a href="#8、模型训练" class="headerlink" title="8、模型训练"></a>8、模型训练</h3>  for i in range(1000):<pre><code>sess.run(train_step, feed_dict={xs: x_data, ys: y_data})</code></pre></li>
<li>feeddict包含的是输入数据，将数据输入至train_step中进行训练。<h3 id="9、代码已上传本人github-其主要根据莫烦代码修改而成。"><a href="#9、代码已上传本人github-其主要根据莫烦代码修改而成。" class="headerlink" title="9、代码已上传本人github,其主要根据莫烦代码修改而成。"></a>9、代码已上传<a href="https://github.com/Gtt-rgb/study_tensorflow" target="_blank" rel="noopener">本人github</a>,其主要根据莫烦代码修改而成。</h3></li>
</ul>
<h3 id="参考文献：1、莫烦tensorflow教程"><a href="#参考文献：1、莫烦tensorflow教程" class="headerlink" title="参考文献：1、莫烦tensorflow教程"></a>参考文献：1、<a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/3-4-A-speed-up-learning/" target="_blank" rel="noopener">莫烦tensorflow教程</a></h3>]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建ROS开发环境</title>
    <url>/2020/03/31/%E6%90%AD%E5%BB%BAROS%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<p><em>本文主要对ros开发环境进行搭建</em></p>
<h2 id="1、针对于python语言开发ROS搭建pycharm开发环境"><a href="#1、针对于python语言开发ROS搭建pycharm开发环境" class="headerlink" title="1、针对于python语言开发ROS搭建pycharm开发环境"></a>1、<a href="https://www.cnblogs.com/thebreakofdawn/p/9249372.html" target="_blank" rel="noopener">针对于python语言开发ROS搭建pycharm开发环境</a></h2><h2 id="2、针对于C-语言开发ROS搭建roboware开发环境"><a href="#2、针对于C-语言开发ROS搭建roboware开发环境" class="headerlink" title="2、针对于C++语言开发ROS搭建roboware开发环境"></a>2、<a href="https://www.cnblogs.com/rjjhyj/p/11460793.html" target="_blank" rel="noopener">针对于C++语言开发ROS搭建roboware开发环境</a></h2><p><strong><em>测试</em></strong></p>
<h3 id="1、ROS下创建第一个节点工程"><a href="#1、ROS下创建第一个节点工程" class="headerlink" title="1、ROS下创建第一个节点工程"></a>1、<a href="https://www.cnblogs.com/blue35sky/p/6078771.html" target="_blank" rel="noopener">ROS下创建第一个节点工程</a></h3><p><strong><em>安装roboware</em></strong></p>
<h3 id="1、roboware的github地址"><a href="#1、roboware的github地址" class="headerlink" title="1、roboware的github地址"></a>1、<a href="https://github.com/tonyrobotics/RoboWare/tree/master/Studio" target="_blank" rel="noopener">roboware的github地址</a></h3>]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu两个python分别同时安装tensorflow</title>
    <url>/2020/03/31/ubuntu%E4%B8%A4%E4%B8%AApython%E5%90%8C%E6%97%B6%E5%AE%89%E8%A3%85tensorflow/</url>
    <content><![CDATA[<blockquote>
<p><strong>本文主要对ubuntu 16.04系统自带python 2.7、python3.5同时安装tensorflow，及验证是否安装成功</strong></p>
</blockquote>
<h2 id="1、两个python安装tensorflow的详细教程"><a href="#1、两个python安装tensorflow的详细教程" class="headerlink" title="1、两个python安装tensorflow的详细教程"></a>1、<a href="https://blog.csdn.net/qq_41833285/article/details/99682549" target="_blank" rel="noopener">两个python安装tensorflow的详细教程</a></h2><h2 id="2、单个python版本tensorflow-gpu的安装"><a href="#2、单个python版本tensorflow-gpu的安装" class="headerlink" title="2、单个python版本tensorflow-gpu的安装"></a>2、<a href="https://blog.csdn.net/sakura__lu/article/details/80622396" target="_blank" rel="noopener">单个python版本tensorflow-gpu的安装</a></h2><h2 id="3、单个python版本tensorflow-gpu的安装2"><a href="#3、单个python版本tensorflow-gpu的安装2" class="headerlink" title="3、单个python版本tensorflow-gpu的安装2"></a>3、<a href="https://blog.csdn.net/macunshi/article/details/84638675" target="_blank" rel="noopener">单个python版本tensorflow-gpu的安装2</a></h2><h2 id="4、测试CUDA是否能用"><a href="#4、测试CUDA是否能用" class="headerlink" title="4、测试CUDA是否能用"></a>4、<a href="https://zhidao.baidu.com/question/1308108448353167699.html" target="_blank" rel="noopener">测试CUDA是否能用</a></h2><h2 id="5、测试tensor-gpu是否可用"><a href="#5、测试tensor-gpu是否可用" class="headerlink" title="5、测试tensor gpu是否可用"></a>5、<a href="https://blog.csdn.net/lidichengfo0412/article/details/102637824" target="_blank" rel="noopener">测试tensor gpu是否可用</a></h2><blockquote>
<p><strong><strong>安装过程存在的问题</strong></strong></p>
</blockquote>
<h3 id="1、运行pip-提示-warning-RequestsDependencyWarning-解决方案"><a href="#1、运行pip-提示-warning-RequestsDependencyWarning-解决方案" class="headerlink" title="1、运行pip 提示(warning, RequestsDependencyWarning)解决方案"></a>1、<a href="https://www.jianshu.com/p/1072e97d5733" target="_blank" rel="noopener">运行pip 提示(warning, RequestsDependencyWarning)解决方案</a></h3><h3 id="2、libcudart-so-8-0-cannot-open-shared-object-file-No-such-file-or-directory-的解决办法"><a href="#2、libcudart-so-8-0-cannot-open-shared-object-file-No-such-file-or-directory-的解决办法" class="headerlink" title="2、libcudart.so.8.0: cannot open shared object file: No such file or directory 的解决办法"></a>2、<a href="https://blog.csdn.net/qq_38451119/article/details/81007904" target="_blank" rel="noopener">libcudart.so.8.0: cannot open shared object file: No such file or directory 的解决办法</a></h3><blockquote>
<p><strong><strong>可选</strong></strong></p>
</blockquote>
<h3 id="1、修改ubuntu两个python优先级"><a href="#1、修改ubuntu两个python优先级" class="headerlink" title="1、修改ubuntu两个python优先级"></a>1、<a href="https://www.cnblogs.com/elitphil/p/11525951.html" target="_blank" rel="noopener">修改ubuntu两个python优先级</a></h3><h3 id="2、ubuntu换源提高下载速度-pip也可设置源"><a href="#2、ubuntu换源提高下载速度-pip也可设置源" class="headerlink" title="2、ubuntu换源提高下载速度(pip也可设置源)"></a>2、<a href="https://blog.csdn.net/u012308586/article/details/102953882" target="_blank" rel="noopener">ubuntu换源提高下载速度(pip也可设置源)</a></h3><blockquote>
<p><strong><strong>注意</strong></strong></p>
</blockquote>
<h3 id="1、在python2-7安装功能包时要用pip2，在python3-5安装功能包时要用pip3！！！！"><a href="#1、在python2-7安装功能包时要用pip2，在python3-5安装功能包时要用pip3！！！！" class="headerlink" title="1、在python2.7安装功能包时要用pip2，在python3.5安装功能包时要用pip3！！！！"></a>1、在python2.7安装功能包时要用pip2，在python3.5安装功能包时要用pip3！！！！</h3><h3 id="2、tensorflow-gpu需要对应相应的cuda与cudnn，详情见tensorflow对应···版本"><a href="#2、tensorflow-gpu需要对应相应的cuda与cudnn，详情见tensorflow对应···版本" class="headerlink" title="2、tensorflow-gpu需要对应相应的cuda与cudnn，详情见tensorflow对应···版本"></a>2、tensorflow-gpu需要对应相应的cuda与cudnn，详情见<a href="https://blog.csdn.net/littlehaes/article/details/100575694" target="_blank" rel="noopener">tensorflow对应···版本</a></h3>]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>针对ros安装存在的rosdep_update问题</title>
    <url>/2020/03/29/%E9%92%88%E5%AF%B9ros%E5%AE%89%E8%A3%85%E5%AD%98%E5%9C%A8%E7%9A%84rosdep-update%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="对于ROS安装存在的rosdep-update与sudo-rosdep-init问题，解决方案如下"><a href="#对于ROS安装存在的rosdep-update与sudo-rosdep-init问题，解决方案如下" class="headerlink" title="对于ROS安装存在的rosdep-update与sudo rosdep init问题，解决方案如下"></a>对于ROS安装存在的rosdep-update与sudo rosdep init问题，解决方案如下</h1><h2 id="1、rosdep-init失败提示error··不能下载、网站不能访问等。"><a href="#1、rosdep-init失败提示error··不能下载、网站不能访问等。" class="headerlink" title="1、rosdep init失败提示error··不能下载、网站不能访问等。"></a>1、rosdep init失败提示error··不能下载、网站不能访问等。</h2><p>  可直接在浏览器访问终端提示的链接，将其内容复制到sourse-list中的20-······文件（文件名在浏览器中已提示）。之后跳过rosdep init即可。</p>
<h2 id="2、对于rosdep-uodate问题，以下三种方法亲测有效。"><a href="#2、对于rosdep-uodate问题，以下三种方法亲测有效。" class="headerlink" title="2、对于rosdep uodate问题，以下三种方法亲测有效。"></a>2、对于rosdep uodate问题，以下三种方法亲测有效。</h2><p>（1）推荐首先使用4g热点尝试。<br>（2）若依旧失败，可修改源，在ubuntu的服务器设置中测试最佳服务器，然后更新，最后终端敲写sudo apt-get update。<br>（3）依旧失败，则终端敲写sudo gedit /etc/resolv.conf，将原有的nameserver这一行注释，并添加以下两行：nameserver 8.8.8.8 #google域名服务器、nameserver 8.8.4.4 #google域名服务器。依次敲写 sudo  apt-get update 、rosdep update。</p>
<hr>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><blockquote>
<p>1、<a href="https://blog.csdn.net/mrh1714348719/article/details/103803110?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">ubuntu安装ROS进行到rosdep update时出现错误，如ERROR: unable to process source …</a><br>2、<a href="https://blog.csdn.net/pj18862486309/article/details/100531506?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">rosdep update 一直失败问题</a></p>
</blockquote>
]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>利用github与hexo搭建个人博客</title>
    <url>/2020/03/26/%E5%88%A9%E7%94%A8github%E4%B8%8Ehexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h2 id="1、B站视频-从0搭建个人博客"><a href="#1、B站视频-从0搭建个人博客" class="headerlink" title="1、B站视频-从0搭建个人博客"></a>1、<a href="https://www.bilibili.com/video/av55890967/" target="_blank" rel="noopener">B站视频-从0搭建个人博客</a></h2><h2 id="2、创建分类与标签"><a href="#2、创建分类与标签" class="headerlink" title="2、创建分类与标签"></a>2、<a href="https://www.cnblogs.com/hankleo/p/11606224.html" target="_blank" rel="noopener">创建分类与标签</a></h2><h2 id="3、本地MarkDown编辑器：MarkDownPad2"><a href="#3、本地MarkDown编辑器：MarkDownPad2" class="headerlink" title="3、本地MarkDown编辑器：MarkDownPad2"></a>3、本地MarkDown编辑器：MarkDownPad2</h2><h2 id="4、博客内显示图片"><a href="#4、博客内显示图片" class="headerlink" title="4、博客内显示图片"></a>4、博客内显示图片</h2><p>（1）post_asset_folder修改为true。<br>（2）git bash安装<code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code>。<br>（3）<code>![](本地图片测试/logo.jpg)</code>。</p>
<p><img src="/2020/03/26/%E5%88%A9%E7%94%A8github%E4%B8%8Ehexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/%E6%97%BA%E8%B4%A2.jpg" alt="测试图片"> </p>
]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/03/26/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
